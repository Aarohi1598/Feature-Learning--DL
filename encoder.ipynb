{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import skimage.transform\n",
    "import skimage.exposure\n",
    "from PIL import ImageFile\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipdb\n",
    "import tensorflow as tf\n",
    "import pickle as cPickle\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "#from tensorflow.python.keras.models "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load Image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_image(path, ori_height=146, ori_width=146, height=128, width=128 ):\n",
    "    \n",
    "    try:\n",
    "        image = skimage.io.imread(path).astype(float)    \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    image = image/255.\n",
    "\n",
    "    if image is None: \n",
    "        return None\n",
    "    if len(image.shape) < 2: \n",
    "        return None\n",
    "    if len(image.shape) == 2: \n",
    "        image=np.tile(image[:,:,None], 3)\n",
    "    if len(image.shape) == 4:\n",
    "        return None\n",
    "    if image.shape[2] == 4: \n",
    "        image=image[:,:,:3]\n",
    "    if image.shape[2] > 4: \n",
    "        return None\n",
    "\n",
    "    shortest_e = min( image.shape[:2] )\n",
    "    y = int((image.shape[0] - shortest_e) / 2)\n",
    "    x = int((image.shape[1] - shortest_e) / 2)\n",
    "    crop_img = image[y:y+shortest_e, x:x+shortest_e]\n",
    "    resize = skimage.transform.resize( crop_img, [ori_height,ori_width] )\n",
    "\n",
    "    rand_y = np.random.randint(0, ori_height - height)\n",
    "    rand_x = np.random.randint(0, ori_width - width)\n",
    "\n",
    "    resize = resize[ rand_y:rand_y+height, rand_x:rand_x+width, : ]\n",
    "    #get_resized_img = (resize*2)-1\n",
    "    # get_resized_img= (resize + 1) / 2\n",
    "    # get_resized_img= skimage.exposure.equalize_hist(resize)\n",
    "    \n",
    "    #plt.imshow(get_resized_img)\n",
    "\n",
    "    return (resize * 2) -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image('dl_project-1/svt1/train/01_16.jpg')\n",
    "img = (img + 1) / 2\n",
    "plt.imshow(img)\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crop Image Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_central(image_ori, width=64,height=64, x=None, y=None, overlap=7):\n",
    "    if image_ori is None: return None\n",
    "    random_y = np.random.randint(overlap,height-overlap) if x is None else x\n",
    "    random_x = np.random.randint(overlap,width-overlap) if y is None else y\n",
    "\n",
    "    image = image_ori.copy()\n",
    "    crop = image_ori.copy()\n",
    "    crop = crop[random_y:random_y+height, random_x:random_x+width]\n",
    "    image[random_y + overlap:random_y+height - overlap, random_x + overlap:random_x+width - overlap, :] = np.array([2*117./255.-1, 2*104./255.-1, 2*123./255.-1])\n",
    "\n",
    "    return image, crop, random_x, random_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img  =  load_image('dl_project-1/svt1/train/01_16.jpg')\n",
    "img = (img + 1) / 2\n",
    "img, _, _, _ = crop_central(img,x=32,y=32)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "           pass\n",
    "   \n",
    "    def conv_layer( self, bottom, filter_shape, activation=tf.identity, padding='SAME', stride=1, name=None ):\n",
    "        with tf.name_scope(name):\n",
    "            w = tf.Variable(tf.random.normal(filter_shape, mean=0.0, stddev=0.005), name=\"W\")\n",
    "            b = tf.Variable(tf.zeros(filter_shape[-1]), name=\"b\")\n",
    "\n",
    "            conv = tf.nn.conv2d(bottom, w, strides=[1, stride, stride, 1], padding=padding)\n",
    "            bias = activation(tf.nn.bias_add(conv, b))\n",
    "        \n",
    "\n",
    "        return bias \n",
    "\n",
    "    def deconv_layer(self, bottom, filter_shape, output_shape, activation=tf.identity, padding='SAME', stride=1, name=None):\n",
    "        with tf.name_scope(name):\n",
    "            W = tf.Variable(tf.random.normal(filter_shape, mean=0.0, stddev=0.005), name=\"W\")\n",
    "            b = tf.Variable(tf.zeros(filter_shape[-2]), name=\"b\")\n",
    "\n",
    "            deconv = tf.nn.conv2d_transpose(bottom, W, output_shape, strides=[1, stride, stride, 1], padding=padding)\n",
    "            bias = activation(tf.nn.bias_add(deconv, b))\n",
    "       \n",
    "        return bias\n",
    "\n",
    "    def fully_conn_layer( self, bottom, output_size, name ):\n",
    "        shape = bottom.get_shape().as_list()\n",
    "        dim = np.prod( shape[1:] )\n",
    "        x = tf.reshape( bottom, [-1, dim])\n",
    "        input_size = dim\n",
    "\n",
    "        with tf.name_scope(name):\n",
    "            w = tf.Variable(tf.random.normal([input_size, output_size], mean=0.0, stddev=0.005), name=\"W\")\n",
    "            b = tf.Variable(tf.zeros([output_size]), name=\"b\")\n",
    "\n",
    "            fully_conn = tf.compat.v1.nn.bias_add( tf.matmul(x, w), b)\n",
    "\n",
    "        return fully_conn\n",
    "\n",
    "    # (7x7x512)\n",
    "    def channel_wise_layer(self, input, name): \n",
    "        _, width, height, n_feat_map = input.get_shape().as_list()\n",
    "        input_reshape = tf.reshape( input, [-1, width*height, n_feat_map] )\n",
    "        input_transpose = tf.transpose( input_reshape, [2,0,1] )\n",
    "\n",
    "        with tf.name_scope(name):\n",
    "            W = tf.Variable(tf.random.normal([n_feat_map, width * height, width * height], mean=0.0, stddev=0.005), name=\"W\")\n",
    "            output = tf.matmul(input_transpose, W)\n",
    "\n",
    "        output_transpose = tf.transpose(output, [1,2,0])\n",
    "        output_reshape = tf.reshape( output_transpose, [-1, height, width, n_feat_map] )\n",
    "\n",
    "        return output_reshape\n",
    "\n",
    "    def leaky_relu(self, bottom, leak=0.1):\n",
    "        return tf.maximum(leak*bottom, bottom)\n",
    "\n",
    "    def batchnorm(self, bottom, is_train, epsilon=1e-8, name=None):\n",
    "        bottom = tf.clip_by_value( bottom, -100., 100.)\n",
    "        depth = bottom.get_shape().as_list()[-1]\n",
    "\n",
    "        with tf.compat.v1.variable_scope(name):\n",
    "\n",
    "            gamma = tf.compat.v1.get_variable(\"gamma\", [depth], initializer=tf.constant_initializer(1.))\n",
    "            beta  = tf.compat.v1.get_variable(\"beta\" , [depth], initializer=tf.constant_initializer(0.))\n",
    "\n",
    "            batch_mean, batch_var = tf.nn.moments(bottom, [0,1,2], name='moments')\n",
    "            exp_ma = tf.compat.v1.train.ExponentialMovingAverage(decay=0.5)\n",
    "\n",
    "\n",
    "            def update():\n",
    "                with tf.control_dependencies([ema_op]):\n",
    "                    return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "            ema_op = exp_ma.apply([batch_mean, batch_var])\n",
    "            ema_mean, ema_var = exp_ma.average(batch_mean), exp_ma.average(batch_var)\n",
    "            mean, var = tf.cond(\n",
    "                    is_train,\n",
    "                    update,\n",
    "                    lambda: (ema_mean, ema_var) )\n",
    "\n",
    "            normalized = tf.compat.v1.nn.batch_norm_with_global_normalization(bottom, mean, var, beta, gamma, epsilon, False)\n",
    "        return normalized\n",
    "\n",
    "    def reconstruction_loss( self, images, is_train ):\n",
    "        batch_size = images.get_shape().as_list()[0]\n",
    "\n",
    "        with tf.compat.v1.variable_scope('GENERATOR3',reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            conv_layer1 = self.conv_layer(images, [4,4,3,64], stride=2, name=\"c1\" )\n",
    "            batch_norm1 = self.leaky_relu(self.batchnorm(conv_layer1, is_train, name='BN1'))\n",
    "            conv_layer2 = self.conv_layer(batch_norm1, [4,4,64,64], stride=2, name=\"c2\" )\n",
    "            batch_norm2 = self.leaky_relu(self.batchnorm(conv_layer2, is_train, name='BN2'))\n",
    "            conv_layer3 = self.conv_layer(batch_norm2, [4,4,64,128], stride=2, name=\"c3\")\n",
    "            batch_norm3 = self.leaky_relu(self.batchnorm(conv_layer3, is_train, name='BN3'))\n",
    "            conv_layer4 = self.conv_layer(batch_norm3, [4,4,128,256], stride=2, name=\"c4\")\n",
    "            batch_norm4 = self.leaky_relu(self.batchnorm(conv_layer4, is_train, name='BN4'))\n",
    "            conv_layer5 = self.conv_layer(batch_norm4, [4,4,256,512], stride=2, name=\"c5\")\n",
    "            batch_norm5 = self.leaky_relu(self.batchnorm(conv_layer5, is_train, name='BN5'))\n",
    "            conv_layer6 = self.conv_layer(batch_norm5, [4,4,512,4000], stride=2, padding='VALID', name='c6')\n",
    "            batch_norm6 = self.leaky_relu(self.batchnorm(conv_layer6, is_train, name='BN6'))\n",
    "\n",
    "            de_conv_layer4 = self.deconv_layer(batch_norm6, [4,4,512,4000], conv_layer5.get_shape().as_list(), padding='VALID', stride=2, name=\"d4\")\n",
    "            de_batch_norm4 = tf.nn.relu(self.batchnorm(de_conv_layer4, is_train, name='DBN4'))\n",
    "            de_conv_layer3 = self.deconv_layer(de_batch_norm4, [4,4,256,512], conv_layer4.get_shape().as_list(), stride=2, name=\"d3\")\n",
    "            de_batch_norm3 = tf.nn.relu(self.batchnorm(de_conv_layer3, is_train, name='DBN3'))\n",
    "            de_conv_layer2 = self.deconv_layer(de_batch_norm3, [4,4,128,256], conv_layer3.get_shape().as_list(), stride=2, name=\"d2\")\n",
    "            de_batch_norm2 = tf.nn.relu(self.batchnorm(de_conv_layer2, is_train, name='DBN2'))\n",
    "            de_conv_layer1 = self.deconv_layer(de_batch_norm2, [4,4,64,128], conv_layer2.get_shape().as_list(), stride=2, name=\"d1\")\n",
    "            de_batch_norm1 = tf.nn.relu(self.batchnorm(de_conv_layer1, is_train, name='DBN1'))\n",
    "            recon = self.deconv_layer(de_batch_norm1, [4,4,3,64], [batch_size,64,64,3], stride=2, name=\"recon\")\n",
    "\n",
    "        return batch_norm1, batch_norm2, batch_norm3, batch_norm4, batch_norm5, batch_norm6, de_batch_norm4, de_batch_norm3, de_batch_norm2, de_batch_norm1, recon, tf.nn.tanh(recon)\n",
    "\n",
    "    def adversarial_loss(self, images, is_train, reuse=True):\n",
    "        with tf.compat.v1.variable_scope('DISCRIMINATOR3', reuse=tf.compat.v1.AUTO_REUSE):\n",
    "            conv_layer1 = self.conv_layer(images, [4,4,3,64], stride=2, name=\"c1\" )\n",
    "            batch_norm1 = self.leaky_relu(self.batchnorm(conv_layer1, is_train, name='BN1'))\n",
    "            conv_layer2 = self.conv_layer(batch_norm1, [4,4,64,128], stride=2, name=\"c2\")\n",
    "            batch_norm2 = self.leaky_relu(self.batchnorm(conv_layer2, is_train, name='BN2'))\n",
    "            conv_layer3 = self.conv_layer(batch_norm2, [4,4,128,256], stride=2, name=\"c3\")\n",
    "            batch_norm3 = self.leaky_relu(self.batchnorm(conv_layer3, is_train, name='BN3'))\n",
    "            conv_layer4 = self.conv_layer(batch_norm3, [4,4,256,512], stride=2, name=\"c4\")\n",
    "            batch_norm4 = self.leaky_relu(self.batchnorm(conv_layer4, is_train, name='BN4'))\n",
    "\n",
    "            output = self.fully_conn_layer(batch_norm4, output_size=1, name='output')\n",
    "\n",
    "        return output[:,0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN IMAGES  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "learning_rate_val = 0.0003\n",
    "weight_decay_rate =  0.0001\n",
    "momentum = 0.9\n",
    "batch_size = 100\n",
    "lambda_recon = 0.999\n",
    "lambda_adv = 0.001\n",
    "overlap_size = 7\n",
    "hiding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_path = 'dl_project-1/svt1/train.pickle'\n",
    "testset_path  = 'dl_project-1/svt1/test.pickle'\n",
    "dataset_path = 'dl_project-1/svt1/'\n",
    "model_path = 'dl_project-1/models/'\n",
    "result_path= 'dl_project-1/results/'\n",
    "pretrained_model_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_path):\n",
    "    os.makedirs( model_path )\n",
    "\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs( result_path )\n",
    "\n",
    "if not os.path.exists( trainset_path ) or not os.path.exists( testset_path ):\n",
    "    \n",
    "    trainset_dir = os.path.join( dataset_path, 'train' )\n",
    "    testset_dir = os.path.join( dataset_path, 'test' )\n",
    "\n",
    "    trainset = pd.DataFrame({'image_path': map(lambda x: os.path.join( trainset_dir, x ), os.listdir(trainset_dir))})\n",
    "    testset = pd.DataFrame({'image_path': map(lambda x: os.path.join( testset_dir, x ), os.listdir(testset_dir))})\n",
    "\n",
    "    trainset.to_pickle( trainset_path )\n",
    "    testset.to_pickle( testset_path )\n",
    "else:\n",
    "    trainset = pd.read_pickle( trainset_path )\n",
    "    testset = pd.read_pickle( testset_path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(testset))\n",
    "testset.index = range(len(testset))\n",
    "testset = testset.iloc[np.random.permutation(len(testset))]\n",
    "is_train = tf.compat.v1.placeholder(tf.bool )\n",
    "\n",
    "learning_rate = tf.compat.v1.placeholder(tf.float32, [])\n",
    "images_tf = tf.compat.v1.placeholder(tf.float32, [batch_size, 128, 128, 3], name=\"images\")\n",
    "print(images_tf)\n",
    "labels_D = tf.concat([tf.ones([batch_size]), tf.zeros([batch_size])], axis=0)\n",
    "labels_G = tf.ones([batch_size])\n",
    "print(labels_D,labels_G)\n",
    "images_hiding = tf.compat.v1.placeholder( tf.float32, [batch_size, hiding_size, hiding_size, 3], name='images_hiding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "batch_norm1, batch_norm2, batch_norm3, batch_norm4, batch_norm5, batch_norm6, de_batch_norm4, de_batch_norm3, de_batch_norm2, de_batch_norm1, reconstruction_ori, reconstruction = model.reconstruction_loss(images_tf, is_train)\n",
    "adversarial_pos = model.adversarial_loss(images_hiding, is_train)\n",
    "adversarial_neg = model.adversarial_loss(reconstruction, is_train, reuse=True)\n",
    "\n",
    "adversarial_pos = tf.expand_dims(adversarial_pos, axis=0)\n",
    "adversarial_neg = tf.expand_dims(adversarial_neg, axis=0)\n",
    "adversarial_all = tf.concat([adversarial_pos, adversarial_neg], axis=0)\n",
    "tf.rank(adversarial_all)\n",
    "print(adversarial_all.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "masking_reconst = tf.pad(tf.ones([hiding_size - 2*overlap_size, hiding_size - 2*overlap_size]), [[overlap_size,overlap_size], [overlap_size,overlap_size]])\n",
    "\n",
    "masking_reconst = tf.expand_dims(masking_reconst, axis=-1)\n",
    "print(masking_reconst.shape)\n",
    "masking_reconst = tf.concat([masking_reconst]*3, axis=-1)\n",
    "masking_overlap = 1 - masking_reconst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon_loss_ori = tf.square( images_hiding - reconstruction )\n",
    "recon_loss_central = tf.reduce_mean(tf.sqrt( 1e-5 + tf.reduce_sum(recon_loss_ori * masking_reconst, [1,2,3])))  # Loss for non-overlapping region\n",
    "recon_loss_overlap = tf.reduce_mean(tf.sqrt( 1e-5 + tf.reduce_sum(recon_loss_ori * masking_overlap, [1,2,3]))) * 10. # Loss for overlapping region\n",
    "recon_loss = recon_loss_central + recon_loss_overlap\n",
    "\n",
    "adversarial_all = tf.reshape(adversarial_all, [-1])\n",
    "adversarial_neg = tf.reshape(adversarial_neg, [-1])\n",
    "loss_adv_D = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(adversarial_all, labels_D))\n",
    "loss_adv_G = tf.reduce_mean( tf.nn.sigmoid_cross_entropy_with_logits(adversarial_neg, labels_G))\n",
    "\n",
    "loss_G = loss_adv_G * lambda_adv + recon_loss * lambda_recon\n",
    "loss_D = loss_adv_D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var_G = list(filter(lambda x: x.name.startswith('GENERATOR'), tf.compat.v1.trainable_variables()))\n",
    "var_D = list(filter(lambda x: x.name.startswith('DISCRIMINATOR'), tf.compat.v1.trainable_variables()))\n",
    "\n",
    "W_G = list(filter(lambda x: x.name.endswith('W:0'), var_G))\n",
    "W_D = list(filter(lambda x: x.name.endswith('W:0'), var_D))\n",
    "\n",
    "loss_G += weight_decay_rate * tf.reduce_mean(tf.stack(list(map(lambda x: tf.nn.l2_loss(x), W_G))))\n",
    "loss_D += weight_decay_rate * tf.reduce_mean(tf.stack(list(map(lambda x: tf.nn.l2_loss(x), W_D))))\n",
    "\n",
    "gpu = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.4)\n",
    "sess = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu))\n",
    "\n",
    "optimizer_G = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5)\n",
    "grads_vars_G = optimizer_G.compute_gradients(loss_G, var_list=var_G)\n",
    "train_op_G = optimizer_G.apply_gradients(grads_vars_G)\n",
    "optimizer_D = tf.compat.v1.train.AdamOptimizer( learning_rate=learning_rate, beta1=0.5 )\n",
    "grads_vars_D = optimizer_D.compute_gradients( loss_D, var_list=var_D )\n",
    "train_op_D = optimizer_D.apply_gradients( grads_vars_D )\n",
    "save_model = tf.compat.v1.train.Saver(max_to_keep=100)\n",
    "# substitute to keras\n",
    "tf.compat.v1.global_variables_initializer().run()\n",
    "\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pretrained_model_path is not None and os.path.exists( pretrained_model_path ):\n",
    "    save_model.restore( sess, pretrained_model_path )\n",
    "\n",
    "i = 0\n",
    "\n",
    "loss_D_val = 0.\n",
    "loss_G_val = 0.\n",
    "loss_G_ad_rec = []\n",
    "loss_D_adv = []\n",
    "print(len(trainset))\n",
    "for epoch in range(n_epochs):\n",
    "    trainset.index = range(len(trainset))\n",
    "    trainset = trainset.iloc[np.random.permutation(len(trainset))]\n",
    "\n",
    "    for start,end in zip(\n",
    "            range(0, len(trainset), batch_size),\n",
    "            range(batch_size, len(trainset), batch_size)):\n",
    "\n",
    "        image_paths = trainset[start:end]['image_path'].values\n",
    "        images_ori = map(lambda x: load_image( x ), image_paths)\n",
    "\n",
    "        images_crops = map(lambda x: crop_central(x), images_ori)\n",
    "        images, crops,_,_ = zip(*images_crops)\n",
    "\n",
    "\n",
    "        if i % 5 == 0:\n",
    "            test_image_paths = testset[:batch_size]['image_path'].values\n",
    "            test_images_ori = map(lambda x: load_image(x), test_image_paths)\n",
    "\n",
    "            test_images_crop = map(lambda x: crop_central(x, x=32, y=32), test_images_ori)\n",
    "            test_images, test_crops, xs,ys = zip(*test_images_crop)\n",
    "\n",
    "            reconstruction_vals, recon_ori_vals, BN1_val,BN2_val,BN3_val,BN4_val,\\\n",
    "            BN5_val,BN6_val,deBN4_val, deBN3_val, deBN2_val, deBN1_val, loss_G_val, loss_D_val = sess.run(\n",
    "                    [reconstruction, reconstruction_ori, batch_norm1,batch_norm2,batch_norm3,batch_norm4,batch_norm5,batch_norm6,de_batch_norm4, de_batch_norm3, de_batch_norm2, de_batch_norm1, loss_G, loss_D],\n",
    "                    feed_dict={\n",
    "                        images_tf: test_images,\n",
    "                        images_hiding: test_crops,\n",
    "                        is_train: False\n",
    "                        })\n",
    "\n",
    "            # Get result after 5 iterations\n",
    "            if i % 5 == 0:\n",
    "                img_no = 0\n",
    "                for rec_val, img,x,y in zip(reconstruction_vals, test_images, xs, ys):\n",
    "                    rec_hid = (255. * (rec_val+1)/2.).astype(int)\n",
    "                    rec_con = (255. * (img+1)/2.).astype(int)\n",
    "\n",
    "                    rec_con[y:y+64, x:x+64] = rec_hid\n",
    "                    cv2.imwrite( os.path.join(result_path, 'img_'+str(img_no)+'.'+str(int(i/1000))+'.jpg'), rec_con)\n",
    "                    img_no += 1\n",
    "                    if img_no > 50: break\n",
    "\n",
    "            print(\"Loss parameter Values at each operation: \")\n",
    "\n",
    "            print(BN1_val.max(), BN1_val.min())\n",
    "            print(BN2_val.max(), BN2_val.min())\n",
    "            print(BN3_val.max(), BN3_val.min())\n",
    "            print(BN4_val.max(), BN4_val.min())\n",
    "            print(BN5_val.max(), BN5_val.min())\n",
    "            print(BN6_val.max(), BN6_val.min())\n",
    "\n",
    "            print(deBN4_val.max(), deBN4_val.min())\n",
    "            print(deBN3_val.max(), deBN3_val.min())\n",
    "            print(deBN2_val.max(), deBN2_val.min())\n",
    "            print(deBN1_val.max(), deBN1_val.min())\n",
    "\n",
    "            print(recon_ori_vals.max(), recon_ori_vals.min())\n",
    "            print(reconstruction_vals.max(), reconstruction_vals.min())\n",
    "            print(loss_G_val, loss_D_val)\n",
    "            print('\\n')\n",
    "\n",
    "            if np.isnan(reconstruction_vals.min() ) or np.isnan(reconstruction_vals.max()):\n",
    "                print(\"NaN detected!!\")\n",
    "                ipdb.set_trace()\n",
    "\n",
    "       \n",
    "        _, loss_G_val, adv_pos_val, adv_neg_val, loss_recon_val, loss_adv_G_val, \\\n",
    "            reconstruction_vals, recon_ori_vals, BN1_val,BN2_val,BN3_val,BN4_val,BN5_val,BN6_val, \\\n",
    "                deBN4_val, deBN3_val, deBN2_val, deBN1_val = sess.run(\n",
    "                [train_op_G, loss_G, adversarial_pos, adversarial_neg,recon_loss, loss_adv_G, reconstruction, reconstruction_ori, \\\n",
    "                batch_norm1,batch_norm2,batch_norm3,batch_norm4,batch_norm5,batch_norm6,\\\n",
    "                de_batch_norm4, de_batch_norm3, de_batch_norm2, de_batch_norm1],\n",
    "                feed_dict={\n",
    "                    images_tf: images,\n",
    "                    images_hiding: crops,\n",
    "                    learning_rate: learning_rate_val,\n",
    "                    is_train: True\n",
    "                    })\n",
    "\n",
    "        loss_G_ad_rec.append(loss_G_val)\n",
    "        loss_D_adv.append(loss_D_val)\n",
    "        # Discriminator of GAN is updated only once in 10 iterations\n",
    "        if i % 5  == 0:\n",
    "            _, loss_D_val, adv_pos_val, adv_neg_val = sess.run(\n",
    "                    [train_op_D, loss_D, adversarial_pos, adversarial_neg],\n",
    "                    feed_dict={\n",
    "                        images_tf: images,\n",
    "                        images_hiding: crops,\n",
    "                        learning_rate: learning_rate_val,\n",
    "                        is_train: True\n",
    "                        })\n",
    "\n",
    "            print(\"Iteration:\", i, \"Generator Loss:\", loss_G_val, \"Reconconstuction Loss:\", loss_recon_val, \"Gen Adversarial Loss:\", loss_adv_G_val,  \"Discriminator Loss:\", loss_D_val, \"==\", adv_pos_val.mean(), adv_neg_val.min(), adv_neg_val.max())\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "    save_model.save(sess, model_path + 'model', global_step=epoch)\n",
    "    learning_rate_val *= 0.99\n",
    "plt.plot(range(len(loss_D_adv)), loss_D_adv, label='Adversarial Loss')\n",
    "plt.plot(range(len(loss_G_ad_rec)), loss_G_ad_rec, label='Reconstruction + Adversarial Loss')\n",
    "#plt.plot(range(len(recon_losses)), recon_losses, label='Reconstruction Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "learning_rate_val =  0.0003\n",
    "weight_decay_rate = 0.0001\n",
    "momentum = 0.9\n",
    "batch_size = 100\n",
    "lambda_recon = 0.999\n",
    "lambda_adv = 0.001\n",
    "overlap_size = 7\n",
    "hiding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = \"dl_project-1/models/checkpoint\"\n",
    "\n",
    "vars_list = tf.train.list_variables(ckpt_path)\n",
    "for var in vars_list:\n",
    "    print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"dl_project-1/models/checkpoint\"\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(\"Checkpoint file exists.\")\n",
    "else:\n",
    "    print(\"Checkpoint file does not exist.\")\n",
    "\n",
    "try:\n",
    "    reader = tf.train.load_checkpoint(checkpoint_path)\n",
    "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
    "except Exception as e:\n",
    "    print(\"Error reading checkpoint file: \", str(e))\n",
    "else:\n",
    "    # Check the integrity of the variables\n",
    "    try:\n",
    "        tf.train.init_from_checkpoint(checkpoint_path, assignment_map=var_to_shape_map)\n",
    "    except Exception as e:\n",
    "        print(\"Integrity check failed: \", str(e))\n",
    "    else:\n",
    "        print(\"Integrity check successful.\")\n",
    "# saver = tf.compat.v1.train.Saver()\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     # Restore the checkpoint\n",
    "#     saver.restore(sess, 'dl_project-1/models/checkpoint')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_path  = 'dl_project-1/svt1/test.pickle'\n",
    "result_path= 'dl_project-1/results/results_test/'\n",
    "pretrained_model_path = 'dl_project-1/models/model-99'\n",
    "testset = pd.read_pickle( testset_path )\n",
    "\n",
    "is_train = tf.compat.v1.placeholder( tf.bool )\n",
    "images_tf = tf.compat.v1.placeholder( tf.float32, [batch_size, 128, 128, 3], name=\"images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "\n",
    "reconstruction = model.reconstruction_loss(images_tf, is_train)\n",
    "\n",
    "\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "\n",
    "tf.compat.v1.global_variables_initializer().run()\n",
    "save_model.restore( sess, pretrained_model_path )\n",
    "\n",
    "n = 0\n",
    "for start,end in zip(\n",
    "        range(0, len(testset), batch_size),\n",
    "        range(batch_size, len(testset), batch_size)):\n",
    "    \n",
    "    test_image_paths = testset[:batch_size]['image_path'].values\n",
    "    test_images_ori = map(lambda x: load_image(x), test_image_paths)\n",
    "\n",
    "    test_images_crop = map(lambda x: crop_central(x, x=32, y=32), test_images_ori)\n",
    "    test_images, test_crops, xs,ys = zip(*test_images_crop)\n",
    "    for img,x,y in zip(test_images, xs, ys):\n",
    "        img_rgb = (255. * (img + 1)/2.).astype(int)\n",
    "        cv2.imwrite(os.path.join(result_path, 'img_'+str(n)+'.ori.jpg'), img_rgb)\n",
    "        n+=1\n",
    "        if n>30: \n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "j_kernel",
   "language": "python",
   "name": "j_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
